{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujuLMxSvoXbg"
      },
      "source": [
        "# Optimization Techniques in Machine Learning\n",
        "\n",
        "Objective: This assignment aims to explore implementation or Machine Learning Models with regularization, optimization and Error analysisÂ  techniques used in machine learning to improve models' performance, convergence speed, and efficiency.\n",
        "\n",
        "A Notebook detailing the following\n",
        "\n",
        "* Project name\n",
        "* Clear out puts from cells\n",
        "\n",
        "**Instructions**\n",
        "1. Acquire a dataset suitable for ML tasks as per your proposal.\n",
        "2. Implement a simple machine learning model based on neural networks on the chosen dataset without any defined optimization techniques. (Check instructions)\n",
        "3. Implement and compare the model's performance after applying 3 to 4 disntict combinations regularization and optimization techniques.\n",
        "4. Discuss the results on the README file.\n",
        "5. Make predictions using test data\n",
        "7. Implement error analysis techniques and ensure there is: F1-Score, Recall, Precision, RUC a confusion matrix using plotting libraries (not verbose)\n",
        "\n",
        "Submit notebook to github repo\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Lq2KwfiNVxi"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGCnpzs9M4Fd"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Import Necessary Libraries\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
          ]
        }
      ],
      "source": [
        "#Import Necessary Libraries\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.regularizers import l1, l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1FN7bFeIxfH"
      },
      "source": [
        "# The Dataset\n",
        "> ***Brief Description:***\n",
        "State the Problem and A short Description of the data\n",
        "\n",
        "---\n",
        "\n",
        "For this project, I'll use the Adult Income Dataset (also known as the \"Census Income\" dataset). This dataset contains information about individuals' income levels based on various features such as age, education, occupation, and more. The goal is to predict whether an individual's income exceeds $50,000 per year. The dataset can be found in the UCI Machine Learning Repository: [Adult Income Dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nas-T7xwPIso"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
        "columns = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"]\n",
        "data = pd.read_csv(url, names=columns, sep=',\\s', na_values=[\"?\"], engine='python')\n",
        "\n",
        "# Drop rows with missing values\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Encode categorical variables\n",
        "label_encoders = {}\n",
        "for column in data.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    data[column] = le.fit_transform(data[column])\n",
        "    label_encoders[column] = le\n",
        "\n",
        "# Split data\n",
        "X = data.drop('income', axis=1)\n",
        "y = data['income']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkxnULN3Lv6P"
      },
      "source": [
        "# Simple Neural Network Model (No Optimization Techniques)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8pdbQVhLzb_",
        "outputId": "332fd71f-5d94-409b-e9b2-b2b8fe859207"
      },
      "outputs": [],
      "source": [
        "# Define a simple neural network model without optimization techniques\n",
        "def simple_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Train the simple model\n",
        "simple_model = simple_model()\n",
        "simple_history = simple_model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
        "\n",
        "# Evaluate the simple model\n",
        "simple_loss, simple_accuracy = simple_model.evaluate(X_test, y_test)\n",
        "print(f\"Simple Model Test Accuracy: {simple_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCeuYfiAN1Fo"
      },
      "source": [
        "# Neural Network Models with Optimization Techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhLy-rPaN32N",
        "outputId": "90d8ebdf-48e7-4496-e272-d1f0a14546b3"
      },
      "outputs": [],
      "source": [
        "# Define a function to create models with optimization techniques\n",
        "def define_model(optimizer, regularization, early_stopping, dropout, learning_rate, layers):\n",
        "    model = Sequential()\n",
        "    for units in layers:\n",
        "        model.add(Dense(units, activation='relu', kernel_regularizer=regularization))\n",
        "        if dropout:\n",
        "            model.add(Dropout(dropout))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer=optimizer(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Model 1: Adam optimizer, L2 regularization, Early stopping\n",
        "model_1 = define_model(Adam, l2(0.01), True, 0.2, 0.001, [64, 32])\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "history_1 = model_1.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
        "\n",
        "# Model 2: RMSprop optimizer, L1 regularization, No Early stopping\n",
        "model_2 = define_model(RMSprop, l1(0.01), False, 0.2, 0.001, [64, 32])\n",
        "history_2 = model_2.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
        "\n",
        "# Model 3: Custom combination\n",
        "model_3 = define_model(Adam, l1(0.01), True, 0.3, 0.01, [128, 64, 32])\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "history_3 = model_3.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
        "\n",
        "# Model 4: Another custom combination\n",
        "model_4 = define_model(RMSprop, l2(0.01), True, 0.2, 0.001, [256, 128, 64])\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "history_4 = model_4.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Z93yBA9N8VL"
      },
      "source": [
        "# Evaluate and Compare Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JriUFmsN_4Y",
        "outputId": "5457e0a5-f18d-406b-d1dc-2bad9e7eea95"
      },
      "outputs": [],
      "source": [
        "# Evaluate each model on the test set\n",
        "models = [simple_model, model_1, model_2, model_3, model_4]\n",
        "histories = [simple_history, history_1, history_2, history_3, history_4]\n",
        "model_names = ['Simple Model', 'Model 1', 'Model 2', 'Model 3', 'Model 4']\n",
        "\n",
        "results = []\n",
        "for model, history, name in zip(models, histories, model_names):\n",
        "    loss, accuracy = model.evaluate(X_test, y_test)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred = (y_pred > 0.5).astype(int)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_pred)\n",
        "    results.append((name, accuracy, f1, recall, precision, roc_auc))\n",
        "\n",
        "# Print results\n",
        "for result in results:\n",
        "    print(f\"Model: {result[0]}\")\n",
        "    print(f\"Accuracy: {result[1]}\")\n",
        "    print(f\"F1 Score: {result[2]}\")\n",
        "    print(f\"Recall: {result[3]}\")\n",
        "    print(f\"Precision: {result[4]}\")\n",
        "    print(f\"ROC AUC: {result[5]}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl51UkPEP15Q"
      },
      "source": [
        "# Error Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "gPrqcTgiP3jK",
        "outputId": "a8497857-dd6e-4312-c946-0547acc11fa4"
      },
      "outputs": [],
      "source": [
        "# Plot confusion matrix for the best model\n",
        "best_model = model_4\n",
        "y_pred = best_model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5).astype(int)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsgfTwIvOHPc"
      },
      "source": [
        "# Save Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4js2kxNOGAP"
      },
      "outputs": [],
      "source": [
        "simple_model.save('saved_models/simple_model.h5')\n",
        "model_1.save('saved_models/model_1.h5')\n",
        "model_2.save('saved_models/model_2.h5')\n",
        "model_3.save('saved_models/model_3.h5')\n",
        "model_4.save('saved_models/model_4.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
